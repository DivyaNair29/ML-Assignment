{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3a2888",
   "metadata": {},
   "source": [
    "1. What is the definition of a target function? In the sense of a real-life example, express the target\n",
    "function. How is a target function&#39;s fitness assessed?\n",
    "\n",
    "Ans: A target function, in machine learning, is a method for solving a problem that an AI algorithm parses its training data to find. Once an algorithm finds its target function, that function can be used to predict results (predictive analysis).The function can then be used to find output data related to inputs for real problems where, unlike training sets, outputs are not included.\n",
    "The target function is essentially the formula that an algorithm feeds data to in order to calculate predictions. As in algebra, it is common when training AI to find the variable from the solution, working in reverse. The function as defined by f is applied to the input (I) to produce the output (I), Therefore O= f(I)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594e7281",
   "metadata": {},
   "source": [
    "2. What are predictive models, and how do they work? What are descriptive types, and how do you\n",
    "use them? Examples of both types of models should be provided. Distinguish between these two\n",
    "forms of models.\n",
    "\n",
    "Ans: Predictive modeling is a mathematical process used to predict future events or outcomes by analyzing patterns in a given set of input data. It is a crucial component of predictive analytics, a type of data analytics which uses current and historical data to forecast activity, behavior and trends. Predictive models are used for all kinds of applications, including weather forecasts, creating video games, translating voice to text, customer service, and investment portfolio strategies. All of these applications use descriptive statistical models of existing data to make predictions about future data. \n",
    "\n",
    "A descriptive model, is describing the data in a form that allows for future action strategies, but it is not a precise event.A descriptive model describes a system or other entity and its relationship to its environment. It is generally used to help specify and/or understand what the system is, what it does, and how it does it. A familiar example of descriptive modeling is business reporting in the form of graphs, charts, and dashboards.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49a33f",
   "metadata": {},
   "source": [
    "3. Describe the method of assessing a classification model&#39;s efficiency in detail. Describe the various\n",
    "measurement parameters.\n",
    "\n",
    "Ans: Methods of assessing a classification model's are:\n",
    "    \n",
    "    1) Accuracy - The most simple and straightforward classification metric is accuracy. Accuracy measures the fraction of correctly classified observations.\n",
    "    \n",
    "    2) Precision and Recall - An alternative measure to accuracy is precision. Precision is the fraction of instances marked as positive that are actually positive. In other words, precision measures “how useful are the results of our classifier”. Another way to look at the TPs is by using recall. Recall is the fraction of true positive instances that are marked to be positive. It measures “how complete the results are” — that is, which percentage of true positives are predicted as positive. \n",
    "    \n",
    "    3) F1 Score - The F-1 score is the harmonic mean of precision and recall. \n",
    "    \n",
    "    4) ROC Curve and AUC - A well-known method to visualize the classification performance is a ROC curve (receiver operating characteristic curve). The plot shows the classifier’s success for different threshold values.\n",
    "    AUC is the area under the ROC curve. In case we have a better classification for each threshold value, the area grows. A perfect classification leads to an AUC of 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8080f8",
   "metadata": {},
   "source": [
    "4.\n",
    "i. In the sense of machine learning models, what is underfitting? What is the most common\n",
    "reason for underfitting?\n",
    "ii. What does it mean to overfit? When is it going to happen?\n",
    "iii. In the sense of model fitting, explain the bias-variance trade-off.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac72d9",
   "metadata": {},
   "source": [
    "Ans: i) Underfitting vs. overfitting the model - Underfitting means that your model makes accurate, but initially incorrect predictions. In this case, train error is large and val/test error is large too.Reasons for Underfitting\n",
    "\n",
    "    1)High bias and low variance. \n",
    "    \n",
    "    2)The size of the training dataset used is not enough. \n",
    "    \n",
    "    3)The model is too simple. 4)Training data is not cleaned and also contains noise in it.\n",
    "\n",
    "ii) Overfitting means that your model makes not accurate predictions. In this case, train error is very small and val/test error is large.Reasons for Overfitting:\n",
    "\n",
    "    1)High variance and low bias.\n",
    "    \n",
    "    2)The model is too complex.\n",
    "    \n",
    "    3)The size of the training data.\n",
    "    \n",
    "iii)\n",
    "\n",
    "    1) Low-Bias, Low-Variance:\n",
    "    The combination of low bias and low variance shows an ideal machine learning model. However, it is not possible practically.\n",
    "    \n",
    "    2)Low-Bias, High-Variance: With low bias and high variance, model predictions are inconsistent and accurate on average. This case occurs when the model learns with a large number of parameters and hence leads to an overfitting\n",
    "    \n",
    "    3)High-Bias, Low-Variance: With High bias and low variance, predictions are consistent but inaccurate on average. This case occurs when a model does not learn well with the training dataset or uses few numbers of the parameter. It leads to underfitting problems in the model.\n",
    "    \n",
    "    4)High-Bias, High-Variance:\n",
    "    With high bias and high variance, predictions are inconsistent and also inaccurate on average.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b821c8",
   "metadata": {},
   "source": [
    "5. Is it possible to boost the efficiency of a learning model? If so, please clarify how.\n",
    "\n",
    "Ans: Yes it is possible to boost the efficiency of a learning model. Model improvements can come from distinct sources:\n",
    "\n",
    "    1)Choice of machine learning or deep learning model\n",
    "    \n",
    "    2)Hyperparameter tuning\n",
    "    \n",
    "    3)Custom loss functions to prioritize metrics as per business needs\n",
    "    \n",
    "    4)Ensembling of models to combine relative strengths of individual models\n",
    "    \n",
    "    5)Novel optimizers that outperform standard optimizers like ReLu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf96fa3c",
   "metadata": {},
   "source": [
    "6. How would you rate an unsupervised learning model&#39;s success? What are the most common\n",
    "success indicators for an unsupervised learning model?\n",
    "\n",
    "Ans: While supervised learning has proved to be effective in various fields (e.g., sentiment analysis), unsupervised learning has the upper hand when it comes to raw data exploration needs.\n",
    "\n",
    "    a)Unsupervised learning is helpful for data science teams that don’t know what they’re looking for in data. It can be used to search for unknown similarities and differences in data and create corresponding groups. For example, user categorization by their social media activity.\n",
    "    \n",
    "    b)The given method doesn’t require training data to be labeled, saving time spent on manual classification tasks.\n",
    "    \n",
    "    c)Unlabeled data is much easier and faster to get.\n",
    "    \n",
    "    d)Such an approach can find unknown patterns and therefore useful insights in data that couldn’t be found otherwise.\n",
    "    \n",
    "    e)It reduces the chance of human error and bias, which could occur during manual labeling processes.\n",
    "\n",
    "Unsupervised learning can be approached through different techniques such as clustering, association rules, and dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df8247",
   "metadata": {},
   "source": [
    "7. Is it possible to use a classification model for numerical data or a regression model for categorical\n",
    "data with a classification model? Explain your answer.\n",
    "\n",
    "Ans: No, it is not possible to use a classification model for numerical data or a regression model for categorical\n",
    "data with a classification model because of the difference in data type and output required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608f58c",
   "metadata": {},
   "source": [
    "8. Describe the predictive modeling method for numerical values. What distinguishes it from\n",
    "categorical predictive modeling?\n",
    "\n",
    "Ans: Machine Learning Regression is a technique for investigating the relationship between independent variables or features and a dependent variable or outcome. It's used as a method for predictive modelling in machine learning, in which an algorithm is used to predict continuous outcomes.\n",
    "In categorical predictive modeling, an algorithm is used to predict classes as outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ace97b6",
   "metadata": {},
   "source": [
    "9. The following data were collected when using a classification model to predict the malignancy of a\n",
    "group of patients&#39; tumors:\n",
    "i. Accurate estimates – 15 cancerous, 75 benign\n",
    "ii. Wrong predictions – 3 cancerous, 7 benign\n",
    "Determine the model&#39;s error rate, Kappa value, sensitivity, precision, and F-measure.\n",
    "\n",
    "Ans: Error Rate = 10/100 = 0.1\n",
    "    \n",
    "    Sensitivity - 15/15+7 = 0.68\n",
    "    \n",
    "    Precision - 15/15+3 = 0.83\n",
    "    \n",
    "    Recall - 15/15+7 = 0.68\n",
    "    \n",
    "    F-measure - 2*(0.83*0.68/0.83+0.68) = 0.74"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b333a19f",
   "metadata": {},
   "source": [
    "10. Make quick notes on:\n",
    "1. The process of holding out\n",
    "2. Cross-validation by tenfold\n",
    "3. Adjusting the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c6aef8",
   "metadata": {},
   "source": [
    "1) The process of holding out - The hold-out method for training a machine learning model is the process of splitting the data into different splits and using one split for training the model and other splits for validating and testing the models. The hold-out method is used for both model evaluation and model selection.\n",
    "\n",
    "2) Cross-validation by tenfold - With this method we have one data set which we divide randomly into 10 parts. We use 9 of those parts for training and reserve one tenth for testing. We repeat this procedure 10 times each time reserving a different tenth for testing.\n",
    "\n",
    "3) Adjusting the parameters - These parameters are known as hyperparameters. Hyperparameters are parameters whose values control the learning process and determine the values of model parameters that a learning algorithm ends up learning. The prefix ‘hyper_’ suggests that they are ‘top-level’ parameters that control the learning process and the model parameters that result from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c3c79",
   "metadata": {},
   "source": [
    "11. Define the following terms:\n",
    "1. Purity vs. Silhouette width\n",
    "2. Boosting vs. Bagging\n",
    "3. The eager learner vs. the lazy learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2e827c",
   "metadata": {},
   "source": [
    "1) Purity vs. Silhouette width - The silhouette width for each cell is defined as the difference between these two values divided by their maximum. Cells with large positive silhouette widths are closer to other cells in the same cluster than to cells in different clusters. Thus, clusters with large positive silhouette widths are well-separated from other clusters.\n",
    "\n",
    "The “clustering purity” is defined for each cell as the proportion of neighboring cells that are assigned to the same cluster, after some weighting to adjust for differences in the number of cells between clusteres. Well-separated clusters should exhibit little intermingling and thus high purity values for all member cells.\n",
    " \n",
    "2) Boosting vs Bagging - Bagging is a method of merging the same type of predictions. Boosting is a method of merging different types of predictions. Bagging decreases variance, not bias, and solves over-fitting issues in a model. Boosting decreases bias, not variance.\n",
    "\n",
    "3) The eager learner vs. the lazy learner - Lazy learning algorithms take a shorter time for training and a longer time for predicting. The eager learning algorithm processes the data while the training phase is only. Eager learning algorithms are faster than lazy learning algorithms for predicting data observations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
