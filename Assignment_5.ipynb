{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4405d641",
   "metadata": {},
   "source": [
    "1. What are the key tasks that machine learning entails? What does data pre-processing imply?\n",
    "\n",
    "Ans: A machine learning task is the type of prediction or inference being made, based on the problem or question that is being asked, and the available data.\n",
    "Data Pre-Processing is a process of preparing the raw data and making it suitable for a machine learning model. It is the first and crucial step while creating a machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04459e6f",
   "metadata": {},
   "source": [
    "2. Describe quantitative and qualitative data in depth. Make a distinction between the two.\n",
    "\n",
    "Ans: Quantitative data is anything that can be counted or measured; it refers to numerical data.Quantitative data can tell you “how many,” “how much,” or “how often”\n",
    "\n",
    "Qualitative data is descriptive, referring to things that can be observed but not measured—such as colors or emotions. Qualitative data also refers to the words or labels used to describe certain characteristics or traits—for example, describing the sky as blue or labeling a particular ice cream flavor as vanilla.\n",
    "\n",
    "The difference are -\n",
    "1) Quantitative data are countable or measurable whereas qualitative data are descriptive, relating to words or language.\n",
    "\n",
    "2) Quantitative data are fixed and universal whereas qualitative datas are dynamic and subjective.\n",
    "\n",
    "3) Quantitative data are gathered by measuring things whereas qualitative datas are gathered through observations and interviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e925987f",
   "metadata": {},
   "source": [
    "3. Create a basic data collection that includes some sample records. Have at least one attribute from\n",
    "each of the machine learning data types.\n",
    "\n",
    "Ans: name = ['Sia', 'Divya', 'Mohit']\n",
    "    \n",
    "    age = [25,30,42]\n",
    "    \n",
    "    mail = ['nhsdn12@gmail.com', 'kgkndf445@gmail.com', 'khhp5678@gmail.com']\n",
    "    \n",
    "    marital_status = ['No', 'Yes', 'Yes']\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79929838",
   "metadata": {},
   "source": [
    "4. What are the various causes of machine learning data issues? What are the ramifications?\n",
    "\n",
    "Ans: Various causes of machine learning data issues are - \n",
    "    \n",
    "1) Inadequate Training Data - The major issue that comes while using machine learning algorithms is the lack of quality as well as quantity of data. Further, data quality is also important for the algorithms to work ideally, but the absence of data quality is also found in Machine Learning applications. Data quality can be affected by some factors as follows:\n",
    "\n",
    "Noisy Data- It is responsible for an inaccurate prediction that affects the decision as well as accuracy in classification tasks.\n",
    "    \n",
    "Incorrect data- It is also responsible for faulty programming and results obtained in machine learning models. Hence, incorrect data may affect the accuracy of the results also.\n",
    "    \n",
    "Generalizing of output data- Sometimes, it is also found that generalizing output data becomes complex, which results in comparatively poor future actions.\n",
    "\n",
    "\n",
    "2) Poor Quality of Data - Noisy data, incomplete data, inaccurate data, and unclean data lead to less accuracy in classification and low-quality results. Hence, data quality can also be considered as a major common problem while processing machine learning algorithms.\n",
    "\n",
    "3) Non-representative training data - If we are using non-representative training data in the model, it results in less accurate predictions. A machine learning model is said to be ideal if it predicts well for generalized cases and provides accurate decisions. If there is less training data, then there will be a sampling noise in the model, called the non-representative training set. It won't be accurate in predictions. To overcome this, it will be biased against one class or a group.\n",
    "\n",
    "4) Overfitting and Underfitting - It negatively affects the performance of the model.\n",
    "\n",
    "5) Data Bias - These errors exist when certain elements of the dataset are heavily weighted or need more importance than others. Biased data leads to inaccurate results, skewed outcomes, and other analytical errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b089b558",
   "metadata": {},
   "source": [
    "5. Demonstrate various approaches to categorical data exploration with appropriate examples.\n",
    "\n",
    "Ans: Categorical data is a collection of information that is divided into groups. Categorical data is analysed using mode and median distributions, where nominal data is analysed with mode while ordinal data uses both.\n",
    "\n",
    "1) Contingency tables and bar plots - A table that summarizes data for two categorical variables in this way is called a contingency table. Each value in the table represents the number of times a particular combination of variable outcomes occurred. A bar plot is a common way to display a single categorical variable. \n",
    "\n",
    "2) Visualizing two categorical variables - We can display the distributions of two categorical variables on a bar plot concurrently. Such plots are generally useful for visualizing the relationship between two categorical variables. Other graphs that can be used are stacked bar plot, dodged bar plot etc.\n",
    "\n",
    "3) Mosaic Plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a101e70d",
   "metadata": {},
   "source": [
    "6. How would the learning activity be affected if certain variables have missing values? Having said\n",
    "that, what can be done about it?\n",
    "\n",
    "Ans: Many machine learning algorithms fail if the dataset contains missing values. However, algorithms like K-nearest and Naive Bayes support data with missing values. You may end up building a biased machine learning model, leading to incorrect results if the missing values are not handled properly.\n",
    "There are various ways to handle missing values to avoid any discrepancies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761add95",
   "metadata": {},
   "source": [
    "7. Describe the various methods for dealing with missing data values in depth.\n",
    "\n",
    "Ans: Various methods for dealing with missing data values are:\n",
    "1) Mean, Median or Mode of the column - If the column has numerical values then the mean, median or mode of the values can be used to replace the missing values in that specific column.\n",
    "\n",
    "2) Drop Missing Values - If the number of missing values is less and there won't be much loss of informations then the missing values can be dropped.\n",
    "\n",
    "3) Replace with the previous or next values - It is possible to replace the missing values in a column with the previous or next value in that column.This method might come in handy when working with time-series data.\n",
    "\n",
    "4) Fill with a constant Value - We can choose a constant value to be used as a replacement for the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058d1fbe",
   "metadata": {},
   "source": [
    "8. What are the various data pre-processing techniques? Explain dimensionality reduction and\n",
    "function selection in a few words.\n",
    "\n",
    "Ans:Data preprocessing is an important step in the data mining process that involves cleaning and transforming raw data to make it suitable for analysis. Some common steps in data preprocessing include:\n",
    "\n",
    "Data Cleaning: This involves identifying and correcting errors or inconsistencies in the data, such as missing values, outliers, and duplicates. Various techniques can be used for data cleaning, such as imputation, removal, and transformation.\n",
    "\n",
    "Data Integration: This involves combining data from multiple sources to create a unified dataset. Data integration can be challenging as it requires handling data with different formats, structures, and semantics. Techniques such as record linkage and data fusion can be used for data integration.\n",
    "\n",
    "Data Transformation: This involves converting the data into a suitable format for analysis. Common techniques used in data transformation include normalization, standardization, and discretization. Normalization is used to scale the data to a common range, while standardization is used to transform the data to have zero mean and unit variance. Discretization is used to convert continuous data into discrete categories.\n",
    "\n",
    "Data Reduction: This involves reducing the size of the dataset while preserving the important information. Data reduction can be achieved through techniques such as feature selection and feature extraction. Feature selection involves selecting a subset of relevant features from the dataset, while feature extraction involves transforming the data into a lower-dimensional space while preserving the important information.\n",
    "\n",
    "Data Discretization: This involves dividing continuous data into discrete categories or intervals. Discretization is often used in data mining and machine learning algorithms that require categorical data. Discretization can be achieved through techniques such as equal width binning, equal frequency binning, and clustering.\n",
    "\n",
    "Data Normalization: This involves scaling the data to a common range, such as between 0 and 1 or -1 and 1. Normalization is often used to handle data with different units and scales. Common normalization techniques include min-max normalization, z-score normalization, and decimal scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9420abbb",
   "metadata": {},
   "source": [
    "Feature Selection - Feature selection is simply selecting and excluding given features without changing them.Remove features with missing values, Remove features with low variance, Remove highly correlated features, Univariate feature selection, Recursive feature elimination, Feature selection using SelectFromModel.\n",
    "\n",
    "Dimensionality Reduction - Dimensionality reduction transforms features into a lower dimension.PCA is one of the dimension reduction technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5838c2",
   "metadata": {},
   "source": [
    "9.i. What is the IQR? What criteria are used to assess it?\n",
    "\n",
    "ii. Describe the various components of a box plot in detail? When will the lower whisker\n",
    "surpass the upper whisker in length? How can box plots be used to identify outliers?\n",
    "\n",
    "\n",
    "Ans: i) A quartile is a type of quantile. The first quartile (Q1), is defined as the middle number between the smallest number and the median of the data set, the second quartile (Q2) – median of the given data set while the third quartile (Q3), is the middle number between the median and the largest value of the data set. The interquartile range (IQR), also called as midspread or middle 50%, or technically H-spread is the difference between the third quartile (Q3) and the first quartile (Q1). It covers the center of the distribution and contains 50% of the observations. IQR = Q3 – Q1.\n",
    "\n",
    "ii) A Box Plot is also known as Whisker plot is created to display the summary of the set of data values having properties like minimum, first quartile, median, third quartile and maximum. In the box plot, a box is created from the first quartile to the third quartile, a vertical line is also there which goes through the box at the median. The data can be distributed between five key ranges, which are as follows:\n",
    "\n",
    "    Minimum: Q1-1.5*IQR\n",
    "    1st quartile (Q1): 25th percentile\n",
    "    Median:50th percentile\n",
    "    3rd quartile(Q3):75th percentile\n",
    "    Maximum: Q3+1.5*IQR\n",
    "\n",
    "The lower whisker covers all the data values from the minimum value up to Q1, that is, the lowest 25% of data values. The upper whisker covers all the data values between Q3 and the maximum value, that is, the highest 25% of data values.\n",
    "An outlier is a value that lies in both extremes of data. In other words, it's a value that lies outside the overall distribution pattern and thus can affect the overall data series. These anomalies are treated as abnormal values that can distort the final insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d38410e",
   "metadata": {},
   "source": [
    "10. Make brief notes on any two of the following:\n",
    "\n",
    "1. Data collected at regular intervals\n",
    "\n",
    "2. The gap between the quartiles\n",
    "\n",
    "3. Use a cross-tab\n",
    "\n",
    "\n",
    "Ans:2) The interquartile range is the difference between upper and lower quartiles. The semi-interquartile range is half the interquartile range. A quartile is a type of quantile. The first quartile (Q1), is defined as the middle number between the smallest number and the median of the data set, the second quartile (Q2) – median of the given data set while the third quartile (Q3), is the middle number between the median and the largest value of the data set. The interquartile range (IQR), also called as midspread or middle 50%, or technically H-spread is the difference between the third quartile (Q3) and the first quartile (Q1). It covers the center of the distribution and contains 50% of the observations. IQR = Q3 – Q1.\n",
    "\n",
    "3) Cross tabulation is a method to quantitatively analyze the relationship between multiple variables. Cross tabulation is usually performed on categorical data — data that can be divided into mutually exclusive groups. Cross tabulations are used to examine relationships within data that may not be readily apparent. Cross tabulation is especially useful for studying market research or survey responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30957902",
   "metadata": {},
   "source": [
    "11. Make a comparison between:\n",
    "\n",
    "1. Data with nominal and ordinal values\n",
    "\n",
    "2. Histogram and box plot\n",
    "\n",
    "3. The average and median\n",
    "\n",
    "\n",
    "Ans:\n",
    "    1) Data with nominal and ordinal values\n",
    "    \n",
    "1. Nominal Data - \n",
    "This is a type of data used to name variables without providing any numerical value. Coined from the Latin nomenclature “Nomen” (meaning name), this data type is a subcategory of categorical data.\n",
    "Nominal data is sometimes called “labelled” or “named” data. Examples of nominal data include name, hair colour, sex etc. \n",
    "\n",
    "2. Ordinal Data -\n",
    "This is a data type with a set order or scale to it. However, this order does not have a standard scale on which the difference in variables in each scale is measured. Although mostly classified as categorical data, it is said to exhibit both categorical and numerical data characteristics making it in between. Its classification under categorical data has to do with the fact that it exhibits more categorical data character. Some ordinal data examples include; Likert scale, interval scale, bug severity, customer satisfaction survey data etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0725be",
   "metadata": {},
   "source": [
    "2) Histogram and box plot\n",
    "\n",
    "i) The histogram - Histograms are a type of bar chart. While the bars on a typical bar chart represent categorical groups, the bars on a histogram represent ranges along a continuous, quantifiable spectrum. In other words, you split the data into bins in order to view the distribution of values within a range. The bins are of equal length (and can be empty), and the bins are contiguous. The height of each bar represents the count (or proportion) of the items in the bin. The number of bins is up to the user, though Metabase will automatically select the number of bins for you.\n",
    "\n",
    "ii) Box Plot - A box and whisker plot—also called a box plot—displays the five-number summary of a set of data. The five-number summary is the minimum, first quartile, median, third quartile, and maximum.\n",
    "In a box plot, we draw a box from the first quartile to the third quartile. A vertical line goes through the box at the median. The whiskers go from each quartile to the minimum or maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fccec9b",
   "metadata": {},
   "source": [
    "3) The average and median\n",
    "\n",
    "i) The Average - Mean is the average of the given numbers and is calculated by dividing the sum of given numbers by the total number of numbers.\n",
    "\n",
    "ii) Median, is the middle value of the given list of data when arranged in an order. The arrangement of data or observations can be made either in ascending order or descending order. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
