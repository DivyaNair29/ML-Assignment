{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd3e9aa",
   "metadata": {},
   "source": [
    "1. In the sense of machine learning, what is a model? What is the best way to train a model?\n",
    "\n",
    "Ans: A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data.\n",
    "The best way to train a model is:\n",
    "1) Begin with existing data.\n",
    "2) Analyze data to identify pattern\n",
    "3) Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc9260",
   "metadata": {},
   "source": [
    "2. In the sense of machine learning, explain the &quot;No Free Lunch&quot; theorem.\n",
    "\n",
    "Ans: According to the “No Free Lunch” theory, there is no one model that works best for every situation. Because the assumptions of a great model for one issue may not hold true for another, it is typical in machine learning to attempt many models to discover the one that performs best for a specific problem. This is especially true in supervised learning, where validation or cross-validation is frequently used to compare the prediction accuracy of many models of various complexity in order to select the optimal model. A good model may also be trained using several methods — for example, linear regression can be learned using normal equations or gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4891d5",
   "metadata": {},
   "source": [
    "3. Describe the K-fold cross-validation mechanism in detail.\n",
    "\n",
    "Ans: K-fold cross-validation approach divides the input dataset into K groups of samples of equal sizes. These samples are called folds. For each learning set, the prediction function uses k-1 folds, and the rest of the folds are used for the test set. This approach is a very popular CV approach because it is easy to understand, and the output is less biased than other methods.\n",
    "The steps for k-fold cross-validation are:\n",
    "\n",
    "    1) Split the input dataset into K groups\n",
    "    2) For each group:\n",
    "        2a) Take one group as the reserve or test data set.\n",
    "        2b) Use remaining groups as the training dataset\n",
    "        2c) Fit the model on the training set and evaluate the performance of the model using the test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc097048",
   "metadata": {},
   "source": [
    "4. Describe the bootstrap sampling method. What is the aim of it?\n",
    "\n",
    "Ans: When a machine learning model is built based on bootstrapped data, the model is trained on the bootstrapped data and then tested on the out of bag (OOB) data. The OOB is the portion of the original population that has never been selected in any of the random samples. Because the model has not seen this data before, the model’s quality can be accurately assessed by testing it. If the model performs well on this OOB test data, that indicates that it should also perform similarly well on new data that it’s later exposed to.\n",
    "\n",
    "The advantages of bootstrapping are that it is a straightforward way to derive the estimates of standard errors and confidence intervals, and it is convenient since it avoids the cost of repeating the experiment to get other groups of sampled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2a385f",
   "metadata": {},
   "source": [
    "5. What is the significance of calculating the Kappa value for a classification model? Demonstrate\n",
    "how to measure the Kappa value of a classification model using a sample collection of results.\n",
    "\n",
    "Ans: Cohen’s Kappa Score is a statistic used to measure the performance of machine learning classification models.The Cohen Kappa Score is used to compare the predicted labels from a model with the actual labels in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ac9658",
   "metadata": {},
   "source": [
    "6. Describe the model ensemble method. In machine learning, what part does it play?\n",
    "\n",
    "Ans: Ensemble methods are techniques that create multiple models and then combine them to produce improved results. Ensemble methods in machine learning usually produce more accurate solutions than a single model would.\n",
    "Types of Ensemble Methods:\n",
    "1) Bagging or Bootstrap Aggregating Method\n",
    "2) Random Forest Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebc3768",
   "metadata": {},
   "source": [
    "7. What is a descriptive model&#39;s main purpose? Give examples of real-world problems that\n",
    "descriptive models were used to solve.\n",
    "\n",
    "Ans: A descriptive model describes a system or other entity and its relationship to its environment. It is generally used to help specify and/or understand what the system is, what it does, and how it does it. A familiar example of descriptive modeling is business reporting in the form of graphs, charts, and dashboards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2a237",
   "metadata": {},
   "source": [
    "8. Describe how to evaluate a linear regression model.\n",
    "\n",
    "Ans: There are 3 main metrics for model evaluation in regression:\n",
    "\n",
    "    1. R Square/Adjusted R Square - R Square measures how much variability in dependent variable can be explained by the model. It is the square of the Correlation Coefficient(R) and that is why it is called R Square.\n",
    "\n",
    "    2. Mean Square Error(MSE)/Root Mean Square Error(RMSE) - MSE is calculated by the sum of square of prediction error which is real output minus predicted output and then divide by the number of data points. Root Mean Square Error(RMSE) is the square root of MSE.\n",
    "\n",
    "    3. Mean Absolute Error(MAE) - Mean Absolute Error(MAE) is similar to Mean Square Error(MSE). However, instead of the sum of square of error in MSE, MAE is taking the sum of the absolute value of error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88637e0",
   "metadata": {},
   "source": [
    "9. Distinguish :\n",
    "\n",
    "1. Descriptive vs. predictive models\n",
    "\n",
    "2. Underfitting vs. overfitting the model\n",
    "\n",
    "3. Bootstrapping vs. cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd1f079",
   "metadata": {},
   "source": [
    "Ans: 1. Descriptive vs. predictive models - \n",
    "A descriptive model, is describing the data in a form that allows for future action strategies, but it is not a precise event.A descriptive model describes a system or other entity and its relationship to its environment. It is generally used to help specify and/or understand what the system is, what it does, and how it does it. A familiar example of descriptive modeling is business reporting in the form of graphs, charts, and dashboards.\n",
    "\n",
    "Predictive modeling is a mathematical process used to predict future events or outcomes by analyzing patterns in a given set of input data. It is a crucial component of predictive analytics, a type of data analytics which uses current and historical data to forecast activity, behavior and trends.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ac093",
   "metadata": {},
   "source": [
    "2. Underfitting vs. overfitting the model - \n",
    "Underfitting means that your model makes accurate, but initially incorrect predictions. In this case, train error is large and val/test error is large too.Reasons for Underfitting\n",
    "\n",
    "    1)High bias and low variance.\n",
    "    2)The size of the training dataset used is not enough.\n",
    "    3)The model is too simple.\n",
    "    4)Training data is not cleaned and also contains noise in it.\n",
    "\n",
    "Overfitting means that your model makes not accurate predictions. In this case, train error is very small and val/test error is large.Reasons for Overfitting:\n",
    "\n",
    "    1)High variance and low bias.\n",
    "    2)The model is too complex.\n",
    "    3)The size of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85b5778",
   "metadata": {},
   "source": [
    "3. Bootstrapping vs. cross-validation - \n",
    "The bootstrap method is a statistical technique for estimating quantities of a population by averaging estimates from multiple small data samples.\n",
    "\n",
    "Cross-validations is a very similar technique to Bootstrapping, with the difference that it selects its samples without replacement; that is, there are no repeated elements in every subset. Selecting k-samples with Cross-Validation is called K-Fold CrossValidation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f3e103",
   "metadata": {},
   "source": [
    "10. Make quick notes on:\n",
    "\n",
    "1. LOOCV.\n",
    "\n",
    "2. F-measurement\n",
    "\n",
    "3. The width of the silhouette\n",
    "\n",
    "4. Receiver operating characteristic curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001a2e2e",
   "metadata": {},
   "source": [
    "1) LOOCV - Leave-One-Out Cross-Validation, or LOOCV, procedure is used to estimate the performance of machine learning algorithms when they are used to make predictions on data not used to train the model.It is a computationally expensive procedure to perform, although it results in a reliable and unbiased estimate of model performance. Although simple to use and no configuration to specify, there are times when the procedure should not be used, such as when you have a very large dataset or a computationally expensive model to evaluate.\n",
    "\n",
    "2) F-measurement - The F-score (also known as the F1 score or F-measure) is a metric used to evaluate the performance of a Machine Learning model. It combines precision and recall into a single score. F-measure formula: F-score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "3) The width of the silhouette - The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. If most objects have a high value, then the clustering configuration is appropriate. Silhouette width is a widely used index for assessing the fit of individual objects in the classification, as well as the quality of clusters and the entire classification.\n",
    "\n",
    "4) Receiver operating characteristic curve - A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.The ROC curve is the plot of the true positive rate (TPR) against the false positive rate (FPR), at various threshold settings. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
